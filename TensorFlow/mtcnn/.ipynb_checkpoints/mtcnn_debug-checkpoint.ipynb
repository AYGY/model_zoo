{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from scipy import misc\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "import detect_face\n",
    "import detect_face2\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzhang/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 70, 70, 4)\n",
      "(1, 70, 70, 2)\n",
      "0.0\n",
      "0.0\n",
      "[0.9564381  0.04356182]\n"
     ]
    }
   ],
   "source": [
    "minsize = 20\n",
    "threshold = [0.6, 0.7, 0.7]\n",
    "factor = 0.709\n",
    "img = misc.imread('/home/lzhang/tmp/0000045/001.jpg')\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "        pnet, rnet, onet = detect_face.create_mtcnn(sess, None)\n",
    "\n",
    "out0, out1 = detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "        pnet2, rnet2, onet2 = detect_face2.create_mtcnn(sess, None)\n",
    "\n",
    "out0_2, out1_2 = detect_face2.detect_face(img, minsize, pnet2, rnet2, onet2, threshold, factor)\n",
    "\n",
    "print(np.sum(np.abs(out0 - out0_2)))\n",
    "print(np.sum(np.abs(out1 - out1_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 250, 3)\n",
      "(1, 70, 70, 4)\n",
      "(1, 70, 70, 2)\n",
      "[-0.04171251 -0.03393787 -0.05021905  0.14131135]\n",
      "[0.9564381  0.04356182]\n",
      "0.99999994\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "print(out0.shape)\n",
    "print(out1.shape)\n",
    "\n",
    "print(out0[0, 68, 36, :])\n",
    "print(out1[0, 68, 36, :])\n",
    "print(np.sum(out1[0, 68, 36, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4-2 : weights (1, 1, 32, 4)\n",
      "conv4-2 : biases (4,)\n",
      "conv4-1 : weights (1, 1, 32, 2)\n",
      "conv4-1 : biases (2,)\n",
      "conv3 : weights (3, 3, 16, 32)\n",
      "conv3 : biases (32,)\n",
      "conv2 : weights (3, 3, 10, 16)\n",
      "conv2 : biases (16,)\n",
      "conv1 : weights (3, 3, 3, 10)\n",
      "conv1 : biases (10,)\n",
      "PReLU1 : alpha (10,)\n",
      "PReLU2 : alpha (16,)\n",
      "PReLU3 : alpha (32,)\n"
     ]
    }
   ],
   "source": [
    "from six import string_types, iteritems\n",
    "\n",
    "data_dict = np.load('/home/lzhang/model_zoo/TensorFlow/mtcnn/det1.npy', encoding='latin1').item()\n",
    "for op_name in data_dict:\n",
    "    for param_name, data in iteritems(data_dict[op_name]):\n",
    "        print(op_name, \":\", param_name, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'pnet/p_net/conv1/kernel:0' shape=(3, 3, 3, 10) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/conv1/bias:0' shape=(10,) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/PReLU1/alpha:0' shape=(1, 1, 10) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/conv2/kernel:0' shape=(3, 3, 10, 16) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/conv2/bias:0' shape=(16,) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/PReLU2/alpha:0' shape=(1, 1, 16) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/conv3/kernel:0' shape=(3, 3, 16, 32) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/conv3/bias:0' shape=(32,) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/PReLU3/alpha:0' shape=(1, 1, 32) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/conv4-1/kernel:0' shape=(1, 1, 32, 2) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/conv4-1/bias:0' shape=(2,) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/conv4-2/kernel:0' shape=(1, 1, 32, 4) dtype=float32>\n",
      "<tf.Variable 'pnet/p_net/conv4-2/bias:0' shape=(4,) dtype=float32>\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "        detect_face.create_mtcnn(sess, None)\n",
    "#     tensor_ops = tf.global_variables()\n",
    "#     for op in tensor_ops:\n",
    "#         print(str(op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Graph().as_default():\n",
    "#     sess = tf.Session()\n",
    "#     with sess.as_default():\n",
    "#         pnet, rnet, onet = detect_face.create_mtcnn(sess, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 250, 3)\n",
      "(40, 30, 3)\n",
      "(30, 40, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzhang/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# from scipy import misc\n",
    "\n",
    "# img = misc.imread('/home/lzhang/tmp/0000045/001.jpg')\n",
    "# print(img.shape)\n",
    "# img2 = cv2.resize(img, (30, 40), interpolation=cv2.INTER_CUBIC)\n",
    "# print(img2.shape)\n",
    "# img3 = cv2.resize(img, (40, 30), interpolation=cv2.INTER_CUBIC)\n",
    "# print(img3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzhang/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "minsize = 20\n",
    "threshold = [0.6, 0.7, 0.7]\n",
    "factor = 0.709\n",
    "img = misc.imread('/home/lzhang/tmp/0000045/001.jpg')\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "        pnet, rnet, onet = detect_face.create_mtcnn(sess, None)\n",
    "\n",
    "out = detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    sess = tf.Session()\n",
    "    with sess.as_default():\n",
    "        pnet2, rnet2, onet2 = detect_face2.create_mtcnn(sess, None)\n",
    "\n",
    "out2 = detect_face2.detect_face(img, minsize, pnet2, rnet2, onet2, threshold, factor)\n",
    "\n",
    "for i in range(len(out)):\n",
    "    print(np.sum(np.abs(out[i] - out2[i])))\n",
    "\n",
    "# print(np.sum(np.abs(out0 - out0_2)))\n",
    "# print(np.sum(np.abs(out1 - out1_2)))\n",
    "\n",
    "# print(np.sum(np.abs(out - out2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lzhang/tmp/0000045/003.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzhang/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/009.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/011.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/008.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/015.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/014.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/007.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/012.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/006.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/013.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/004.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/002.jpg\n",
      "0.0\n",
      "0.0\n",
      "/home/lzhang/tmp/0000045/001.jpg\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "minsize = 20\n",
    "threshold = [0.6, 0.7, 0.7]\n",
    "factor = 0.709\n",
    "img_dir = '/home/lzhang/tmp/0000045/'\n",
    "\n",
    "imgs = os.listdir(img_dir)\n",
    "img_paths = [os.path.join(img_dir, img) for img in imgs]\n",
    "\n",
    "for img_path in img_paths:\n",
    "    print(img_path)\n",
    "    img = misc.imread(img_path)\n",
    "    with tf.Graph().as_default():\n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = detect_face.create_mtcnn(sess, None)\n",
    "\n",
    "    out = detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            pnet2, rnet2, onet2 = detect_face2.create_mtcnn(sess, None)\n",
    "\n",
    "    out2 = detect_face2.detect_face(img, minsize, pnet2, rnet2, onet2, threshold, factor)\n",
    "\n",
    "    for i in range(len(out)):\n",
    "        print(np.sum(np.abs(out[i] - out2[i])))\n",
    "\n",
    "# print(np.sum(np.abs(out0 - out0_2)))\n",
    "# print(np.sum(np.abs(out1 - out1_2)))\n",
    "\n",
    "# print(np.sum(np.abs(out - out2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Creating networks and loading parameters\n",
      "INFO:tensorflow:Restoring parameters from /home/lzhang/tmp/saved_model/model.ckpt\n",
      "/home/lzhang/tmp/0000045/003.jpg\n",
      "/home/lzhang/tmp/0000045/009.jpg\n",
      "/home/lzhang/tmp/0000045/011.jpg\n",
      "/home/lzhang/tmp/0000045/008.jpg\n",
      "/home/lzhang/tmp/0000045/015.jpg\n",
      "/home/lzhang/tmp/0000045/014.jpg\n",
      "/home/lzhang/tmp/0000045/007.jpg\n",
      "/home/lzhang/tmp/0000045/012.jpg\n",
      "/home/lzhang/tmp/0000045/006.jpg\n",
      "/home/lzhang/tmp/0000045/013.jpg\n",
      "/home/lzhang/tmp/0000045/005.jpg\n",
      "/home/lzhang/tmp/0000045/004.jpg\n",
      "/home/lzhang/tmp/0000045/002.jpg\n",
      "/home/lzhang/tmp/0000045/001.jpg\n",
      "/home/lzhang/tmp/saved_model/checkpoint\n",
      "/home/lzhang/tmp/saved_model/checkpoint: cannot identify image file '/home/lzhang/tmp/saved_model/checkpoint'\n",
      "/home/lzhang/tmp/saved_model/model.meta\n",
      "/home/lzhang/tmp/saved_model/model.meta: cannot identify image file '/home/lzhang/tmp/saved_model/model.meta'\n",
      "/home/lzhang/tmp/saved_model/model.ckpt.data-00000-of-00001\n",
      "/home/lzhang/tmp/saved_model/model.ckpt.data-00000-of-00001: cannot identify image file '/home/lzhang/tmp/saved_model/model.ckpt.data-00000-of-00001'\n",
      "/home/lzhang/tmp/saved_model/model.ckpt.index\n",
      "/home/lzhang/tmp/saved_model/model.ckpt.index: cannot identify image file '/home/lzhang/tmp/saved_model/model.ckpt.index'\n",
      "Total number of images: 18\n",
      "Number of successfully aligned images: 14\n"
     ]
    }
   ],
   "source": [
    "import mtcnn\n",
    "import mtcnn2\n",
    "import argparse\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "args = argparse.Namespace(detect_multiple_faces=False, gpu_memory_fraction=1.0, image_size=182, input_dir='/home/lzhang/tmp/', margin=44, output_dir='/home/lzhang/mtcnn_result', random_order=False)\n",
    "# args2 = argparse.Namespace(detect_multiple_faces=False, gpu_memory_fraction=1.0, image_size=182, input_dir='/home/lzhang/tmp/', margin=44, output_dir='/home/lzhang/mtcnn_result2', random_order=False)\n",
    "\n",
    "out = mtcnn.main(args)\n",
    "# out2 = mtcnn2.main(args2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/lzhang/mtcnn_result/saved_model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_dir = '/home/lzhang/mtcnn_result/saved_model'\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    detect_face.load_mtcnn(sess, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzhang/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "img = misc.imread('/home/lzhang/tmp/0000045/001.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "img = img.astype(dtype=np.str)\n",
    "# print(img[0])\n",
    "\n",
    "with open('/home/lzhang/tmp/0000045/001.jpg', 'rb') as f:\n",
    "    str = base64.b64encode(f.read())\n",
    "    print(type(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/lzhang/model_zoo/TensorFlow/mtcnn/saved_model\n",
      "/home/lzhang/model_zoo/TensorFlow/mtcnn/saved_model\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/home/lzhang/mtcnn_result/saved_model; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-879380a9dd45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/lzhang/model_zoo/TensorFlow/mtcnn'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexport_mtcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_mtcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/model_zoo/TensorFlow/mtcnn/export_mtcnn.py\u001b[0m in \u001b[0;36mexport_mtcnn\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading model from'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mexport_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'export_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/model_zoo/TensorFlow/mtcnn/export_mtcnn.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_path, sess)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mlatest_checkpoint\u001b[0;34m(checkpoint_dir, latest_filename)\u001b[0m\n\u001b[1;32m   1855\u001b[0m     v1_path = _prefix_to_checkpoint_path(ckpt.model_checkpoint_path,\n\u001b[1;32m   1856\u001b[0m                                          saver_pb2.SaverDef.V1)\n\u001b[0;32m-> 1857\u001b[0;31m     if file_io.get_matching_files(v2_path) or file_io.get_matching_files(\n\u001b[0m\u001b[1;32m   1858\u001b[0m         v1_path):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mget_matching_files\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    335\u001b[0m           \u001b[0;31m# Convert the filenames to string from bytes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0msingle_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m           for matching_filename in pywrap_tensorflow.GetMatchingFiles(\n\u001b[1;32m    339\u001b[0m               compat.as_bytes(single_filename), status)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /home/lzhang/mtcnn_result/saved_model; No such file or directory"
     ]
    }
   ],
   "source": [
    "import export_mtcnn\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "path = '/home/lzhang/model_zoo/TensorFlow/mtcnn'\n",
    "\n",
    "export_mtcnn.export_mtcnn(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow3)",
   "language": "python",
   "name": "tensorflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
