{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import importlib\n",
    "import argparse\n",
    "import facenet\n",
    "import lfw\n",
    "import h5py\n",
    "import math\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python.ops import data_flow_ops\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    network = importlib.import_module(args.model_def)\n",
    "    image_size = (args.image_size, args.image_size)\n",
    "    \n",
    "    subdir = datetime.strftime(datatime.now(), '%Y%m%d-%H%M%S')\n",
    "    log_dir = os.path.join(os.path.expanduser(args.logs_base_dir), subdir)\n",
    "    if not os.path.isdir(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    model_dir = os.path.join(os.path.expanduser(args.models_base_dir), subdir)\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "        \n",
    "    stat_file_name = os.path.join(log_dir, 'stat.h5')\n",
    "    \n",
    "    facenet.write_arguments_to_file(args, os.path.join(log_dir, 'arguments.txt'))\n",
    "    \n",
    "    src_path,_ = os.path.split(os.path.realpath(__file__))\n",
    "    facenet.store_revision_info(src_path, log_dir, ' '.join(sys.argv))\n",
    "    \n",
    "    np.random.seed(seed=args.seed)\n",
    "    random.seed(args.seed)\n",
    "    dataset = facenet.get_dataset(args.data_dir)\n",
    "\n",
    "    if args.validation_set_split_ratio > 0.0:\n",
    "        train_set, val_set = facenet.split_dataset(dataset, args.validation_set_split_ratio, args.min_nrof_val_images_per_class, \n",
    "                                                   'SPLIT_IMAGES')\n",
    "    else:\n",
    "        train_set, val_set = dataset, []    \n",
    "    \n",
    "    num_classes = len(train_set)\n",
    "\n",
    "    print('Model directory: %s' % model_dir)\n",
    "    print('Log directory: %s' % log_dir)\n",
    "    \n",
    "    \n",
    "    pretrained_model = None\n",
    "    if args.pretrained_model:\n",
    "        pretrained_model = os.path.expanduser(args.pretrained_model)\n",
    "        print('Pre-trained model: %s' % pretrained_model)\n",
    "        \n",
    "    if args.lfw_dir:\n",
    "        print('LFW directory: %s' % args.lfw_dir)\n",
    "        pairs = lfw.read_pairs(os.path.expanduser(args.lfw_pairs))\n",
    "        lfw_paths, actual_issame = lfw.get_paths(os.path.expanduser(args.lfw_dir), pairs)\n",
    "        \n",
    "    with tf.Graph().as_default():\n",
    "        tf.set_random_state(args.seed)\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        \n",
    "        image_list, label_list = facenet.get_image_paths_and_labels(train_set)\n",
    "        assert len(image_list) > 0, 'The training set should not be empty'\n",
    "        \n",
    "        val_image_list, val_label_list = facenet.get_image_paths_and_labels(val_set)\n",
    "        \n",
    "        labels = ops.convert_to_tensor(label_list, dtype=tf.int32)\n",
    "        range_size = array_ops.shape(labels)[0]\n",
    "        index_q = tf.train.range_input_producer(range_size, num_epochs=None, shuffle=True, seed=None, capacity=32)\n",
    "        index_deq_op = index_q.dequeue_many(args.batch_size * args.epoch_size, 'index_dequeue')\n",
    "        \n",
    "        learning_rate_placeholder = tf.placeholder(tf.float32, name='learning_rate')\n",
    "        batch_size_placeholder = tf.placeholder(tf.int32, name='batch_size')\n",
    "        phase_train_placeholder = tf.placeholder(tf.bool, name='phase_train')\n",
    "        image_paths_placeholder = tf.placeholder(tf.string, shape=(None, 1), name='image_paths')\n",
    "        labels_placeholder = tf.placeholder(tf.int32, shape=(None, 1), name='labels')\n",
    "        control_placeholder = tf.placeholder(tf.int32, shape=(None, 1), name='control')\n",
    "        \n",
    "        num_preprocess_threads = 4\n",
    "        input_q = data_flow_ops.FIFOQueue(capacity=2000000, shared_name=None, name=None,\n",
    "                                         dtype=[tf.string, tf.int32, tf.int32], \n",
    "                                         shapes=[(1, ), (1, ), (1, )])\n",
    "        enq_op = input_q.enqueue_many([image_paths_placeholder, labels_placeholder, control_placeholder], name='enq_op')\n",
    "\n",
    "        image_batch, label_batch = facenet.create_input_pipeline(input_q, image_size, num_preprocess_threads, batch_size_placeholder)\n",
    "        \n",
    "        image_batch = tf.identity(image_batch, 'image_batch')\n",
    "        image_batch = tf.identity(image_batch, 'input')\n",
    "        label_batch = tf.identity(label_batch, 'label_batch')\n",
    "        \n",
    "        print('Number of classes in training set: %d' % nrof_classes)\n",
    "        print('Number of examples in training set: %d' % len(image_list))\n",
    "        print('Number of classes in validation set: %d' % len(val_set))\n",
    "        print('Number of examples in validation set: %d' % len(val_image_list))\n",
    "        print('Building training graph')        \n",
    "        \n",
    "        prelogits, _ = network.inference(image_batch, args.keep_probability, phase_train=phase_train_placeholder, \n",
    "                                         bottleneck_layer_size=args.embedding_size, weight_decay=args.weight_decay)\n",
    "        \n",
    "        logits = slim.fully_connected(prelogits, num_classes, activation_fn=None, reuse=False, scope='Logits', \n",
    "                                     weights_initializer=slim.initializers.xavier_initializer(), \n",
    "                                     weights_regularizer=slim.l2_regularizer(args.weight_decay))\n",
    "        \n",
    "        embeddings = tf.nn.l2_normalize(prelogits, 1, 1e-10, name='embeddings')\n",
    "        \n",
    "        eps = 1e-4\n",
    "        prelogits_norm = tf.reduce_mean(tf.norm(tf.abs(prelogits) + eps, ord=args.prelogits_norm_p, axis=1))\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, prelogits_norm * args.prelogits_norm_loss_factor)\n",
    "        \n",
    "        prelogits_center_loss, _ = facenet.center_loss(prelogits, label_batch, args.center_loss_alfa, num_classes)\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, prelogits_center_loss * args.center_loss_factor)\n",
    "\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label_batch, logits=logits, name='cross_entropy_per_example')\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "        tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "        regularization_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)        \n",
    "        total_loss = tf.add_n([cross_entropy_mean] + regularization_loss, name='total_loss')\n",
    "\n",
    "        correct_prediction = tf.cast(tf.equal(tf.argmax(logits, 1), tf.cast(label_batch, tf.int64)), tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "        \n",
    "        learning_rate = tf.train.exponential_decay(learning_rate_placeholder, global_step, \n",
    "                                                  args.learning_rate_decay_epochs * args.epoch_size, \n",
    "                                                  args.learning_rate_decay_factor, staircase=True,)\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        \n",
    "        train_op = facenet.train(total_loss, global_step, args.optimizer, learning_rate, \n",
    "                                args.moving_average_decay, tf.global_variables(), args.log_histograms)\n",
    "\n",
    "        saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=3)\n",
    "        \n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n",
    "\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "        coord = tf.train.Coordinator()\n",
    "        tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "        \n",
    "        with sess.as_default():\n",
    "            if pretrained_model:\n",
    "                print('Restoring pretrained model: %s' % pretrained_model)\n",
    "                saver.restore(sess, pretrained_model)\n",
    "            \n",
    "            print('Running training')\n",
    "            num_steps = args.max_nrof_epochs * args.epoch_size\n",
    "            num_val_samples = int(math.ceil(args.max_nrof_epochs / args.validate_every_n_epochs))\n",
    "            \n",
    "            stat = {\n",
    "                'loss': np.zeros((num_steps,), np.float32),\n",
    "                'center_loss': np.zeros((num_steps,), np.float32),\n",
    "                'reg_loss': np.zeros((num_steps,), np.float32),\n",
    "                'xent_loss': np.zeros((num_steps,), np.float32),\n",
    "                'prelogits_norm': np.zeros((num_steps,), np.float32),\n",
    "                'accuracy': np.zeros((num_steps,), np.float32),\n",
    "                'val_loss': np.zeros((num_val_samples,), np.float32),\n",
    "                'val_xent_loss': np.zeros((num_val_samples,), np.float32),\n",
    "                'val_accuracy': np.zeros((num_val_samples,), np.float32),\n",
    "                'lfw_accuracy': np.zeros((args.max_nrof_epochs,), np.float32),\n",
    "                'lfw_valrate': np.zeros((args.max_nrof_epochs,), np.float32),\n",
    "                'learning_rate': np.zeros((args.max_nrof_epochs,), np.float32),\n",
    "                'time_train': np.zeros((args.max_nrof_epochs,), np.float32),\n",
    "                'time_validate': np.zeros((args.max_nrof_epochs,), np.float32),\n",
    "                'time_evaluate': np.zeros((args.max_nrof_epochs,), np.float32),\n",
    "                'prelogits_hist': np.zeros((args.max_nrof_epochs, 1000), np.float32),\n",
    "              }\n",
    "            \n",
    "            for epoch in range(1, args.max_nrof_epochs + 1):\n",
    "                step = sess.run(global_step, feed_dict=None)\n",
    "                t = time.time()\n",
    "                cont = train(args, sess, epoch, image_list, label_list, index_dequeue_op, enqueue_op, \n",
    "                             image_paths_placeholder, labels_placeholder, learning_rate_placeholder, phase_train_placeholder, \n",
    "                             batch_size_placeholder, control_placeholder, global_step, total_loss, train_op, summary_op, \n",
    "                             summary_writer, regularization_losses, args.learning_rate_schedule_file, stat, cross_entropy_mean, \n",
    "                             accuracy, learning_rate, prelogits, prelogits_center_loss, args.random_rotate, args.random_crop, \n",
    "                             args.random_flip, prelogits_norm, args.prelogits_hist_max, args.use_fixed_image_standardization)\n",
    "                stat['time_train'][epoch - 1] = time.time() - t\n",
    "                \n",
    "                if not cont:\n",
    "                    break\n",
    "                    \n",
    "                t = time.time()\n",
    "                if len(val_image_list)>0 and ((epoch-1) % args.validate_every_n_epochs == args.validate_every_n_epochs-1 or \n",
    "                                              epoch==args.max_nrof_epochs):\n",
    "                    validate(args, sess, epoch, val_image_list, val_label_list, enqueue_op, image_paths_placeholder, \n",
    "                             labels_placeholder, control_placeholder, phase_train_placeholder, batch_size_placeholder, stat, \n",
    "                             total_loss, regularization_losses, cross_entropy_mean, accuracy, args.validate_every_n_epochs, \n",
    "                             args.use_fixed_image_standardization)\n",
    "                    stat['time_validate'][epoch - 1] = time.time() - t\n",
    "                    \n",
    "                save_variables_and_metagraph(sess, saver, summary_writer, model_dir, subdir, epoch)\n",
    "                \n",
    "                t = time.time()\n",
    "                if args.lfw_dir:\n",
    "                    evaluate(sess, enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, \n",
    "                             batch_size_placeholder, control_placeholder, embeddings, label_batch, lfw_paths, actual_issame, \n",
    "                             args.lfw_batch_size, args.lfw_nrof_folds, log_dir, step, summary_writer, stat, epoch, \n",
    "                             args.lfw_distance_metric, args.lfw_subtract_mean, args.lfw_use_flipped_images, \n",
    "                             args.use_fixed_image_standardization)\n",
    "                    stat['time_evaluate'][epoch - 1] = time.time() - t\n",
    "                \n",
    "                print('Saving statistics')\n",
    "                with h5py.File(stat_file_name, 'w') as f:\n",
    "                    for key, value in stat.items():\n",
    "                        f.create_dataset(key, data=value)\n",
    "    return model_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, sess, epoch, image_list, label_list, index_dequeue_op, enqueue_op, image_paths_placeholder, labels_placeholder, \n",
    "          learning_rate_placeholder, phase_train_placeholder, batch_size_placeholder, control_placeholder, step, loss, train_op, \n",
    "          summary_op, summary_writer, reg_losses, learning_rate_schedule_file, stat, cross_entropy_mean, accuracy, learning_rate, \n",
    "          prelogits, prelogits_center_loss, random_rotate, random_crop, random_flip, prelogits_norm, prelogits_hist_max, \n",
    "          use_fixed_image_standardization):\n",
    "    batch_number = 0\n",
    "    \n",
    "    if args.learning_rate > 0.0:\n",
    "        lr = args.learning_rate\n",
    "    else:\n",
    "        lr = facenet.get_learning_rate_from_file(learning_rate_schedule_file, epoch)\n",
    "    \n",
    "    if lr <= 0:\n",
    "        return False\n",
    "    \n",
    "    index_epoch = sess.run(index_dequeue_op)\n",
    "    image_epoch = np.array(image_list)[index_epoch]\n",
    "    label_epoch = np.array(label_list)[index_epoch]\n",
    "    \n",
    "    labels_array = np.expand_dims(np.array(label_epoch), 1)\n",
    "    image_path_array = np.expand_dims(np.array(image_epoch), 1)\n",
    "    control_value = facenet.RANDOM_ROTATE * random_rotate + facenet.RANDOM_CROP * random_crop + \\\n",
    "        facenet.RANDOM_FLIP * random_flip + facenet.FIXED_STANDARDIZATION * use_fixed_image_standardization    \n",
    "    control_array = np.ones_like(labels_array) * control_value\n",
    "    \n",
    "    sess.run(enqueue_op, {image_paths_placeholder: image_path_array, labels_placeholder: labels_array, \n",
    "                          control_placeholder: control_array})\n",
    "    \n",
    "    train_time = 0\n",
    "    while batch_number < args.epoch_size:\n",
    "        start_time = time.time()\n",
    "        feed_dict = {learning_rate_placeholder: lr, phase_train_placeholder: True, batch_size_placeholder: args.batch_size}\n",
    "        tensor_list = [loss, train_op, step, reg_losses, prelogits, cross_entropy_mean, leraning_rate, prelogits_norm, \n",
    "                       accuracy, prelogits_center_loss]\n",
    "        \n",
    "        if batch_number % 100 == 0:\n",
    "            _loss, _, _step, _reg_losses, _prelogits, _cross_entropy_mean, _lr, _prelogits_norm, _accuracy, \\\n",
    "            _center_loss, summary_str = sess.run(tensor_list + [summary_op], feed_dict=feed_dict)\n",
    "        else:\n",
    "            _loss, _, _step, _reg_losses, _prelogits, _cross_entropy_mean, _lr, _prelogits_norm, _accuracy, \\\n",
    "            _center_loss = sess.run(tensor_list, feed_dict=feed_dict)            \n",
    "            \n",
    "        duration = time.time() - start_time\n",
    "        stat['loss'][_step - 1] = _loss\n",
    "        stat['center_loss'][_step - 1] = _center_loss\n",
    "        stat['reg_loss'][_step - 1] = np.sum(_reg_losses)\n",
    "        stat['xent_loss'][_step - 1] = _cross_entropy_mean\n",
    "        stat['prelogits_norm'][_step - 1] = _prelogits_norm\n",
    "        stat['learning_rate'][epoch - 1] = _lr\n",
    "        stat['accuracy'][_step - 1] = _accuracy\n",
    "        stat['prelogits_hist'][epoch - 1,:] += np.histogram(np.minimum(np.abs(_prelogits), prelogits_hist_max), \n",
    "                                                            bins=1000, range=(0.0, prelogits_hist_max))[0]\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        print('Epoch: [%d][%d/%d]\\tTime %.3f\\tLoss %2.3f\\tXent %2.3f\\tRegLoss %2.3f\\tAccuracy %2.3f\\tLr %2.5f\\tCl %2.3f' %\n",
    "              (epoch, batch_number + 1, args.epoch_size, duration, _loss, _cross_entropy_mean, np.sum(_reg_losses), \n",
    "               _accuracy, _lr, _center_loss))\n",
    "        batch_number += 1\n",
    "        train_time += duration\n",
    "        \n",
    "    summary = tf.Summary()\n",
    "    summary.value.add(tag='time/total', simple_value=train_time)\n",
    "    summary_writer.add_summary(summary, global_step=_step)\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(args, sess, epoch, image_list, label_list, enqueue_op, image_paths_placeholder, labels_placeholder, \n",
    "             control_placeholder, phase_train_placeholder, batch_size_placeholder, stat, loss, regularization_losses, \n",
    "             cross_entropy_mean, accuracy, validate_every_n_epochs, use_fixed_image_standardization):\n",
    "    print('Running forward pass on validation set')\n",
    "    \n",
    "    num_batches = len(label_list) // args.lfw_batch_size\n",
    "    num_images = num_batches * args.lfw_batch_size\n",
    "    \n",
    "    labels_array = np.expand_dims(np.array(label_list[:num_images]), 1)\n",
    "    image_paths_array = np.expand_dims(np.array(image_list[:num_images]), 1)\n",
    "    control_array = np.ones_like(labels_array, np.int32) * facenet.FIXED_STANDARDIZATION * use_fixed_image_standardization\n",
    "    \n",
    "    sess.run(enqueue_op, {image_paths_placeholder: image_paths_array, labels_placeholder: labels_array, \n",
    "                          control_placeholder: control_array})\n",
    "    \n",
    "    loss_array = np.zeros((num_batches, ), np.float32)\n",
    "    xent_array = np.zeros((num_batches, ), np.float32)\n",
    "    accuracy_array = np.zeros((num_batches, ), np.float32)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i in range(num_batches):\n",
    "        feed_dict = {phase_train_placeholder: False, batch_size_placeholder: args.lfw_batch_size}\n",
    "        _loss, _cross_entropy_mean, _accuracy = sess.run([loss, cross_entropy_mean, accuracy], feed_dict=feed_dict)\n",
    "        loss_array[i], xent_array[i], accuracy_array[i] = (_loss, _cross_entropy_mean, _accuracy)\n",
    "        if i % 10 == 9:\n",
    "            print('.', end='')\n",
    "            sys.stdout.flush()\n",
    "    print('')\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    val_index = (epoch - 1) // validate_every_n_epochs\n",
    "    stat['val_loss'][val_index] = np.mean(loss_array)\n",
    "    stat['val_xent_loss'][val_index] = np.mean(xent_array)\n",
    "    stat['val_accuracy'][val_index] = np.mean(accuracy_array)\n",
    "\n",
    "    print('Validation Epoch: %d\\tTime %.3f\\tLoss %2.3f\\tXent %2.3f\\tAccuracy %2.3f' %\n",
    "          (epoch, duration, np.mean(loss_array), np.mean(xent_array), np.mean(accuracy_array)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sess, enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, batch_size_placeholder, \n",
    "             control_placeholder, embeddings, labels, image_paths, actual_issame, batch_size, nrof_folds, log_dir, step, \n",
    "             summary_writer, stat, epoch, distance_metric, subtract_mean, use_flipped_images, use_fixed_image_standardization):\n",
    "    print('Runnning forward pass on LFW images')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    num_embeddings = len(actual_issame) * 2\n",
    "    num_flips = 2 if use_flipped_images else 1\n",
    "    num_images = num_embeddings * num_flips\n",
    "    labels_array = np.expand_dims(np.arange(num_images, ), 1)\n",
    "    image_path_array = np.expand_dims(np.repeat(np.array(image_paths), num_flips), 1)\n",
    "    control_array = np.zeros_like(labels_array, np.int32)\n",
    "    \n",
    "    if use_fixed_image_standardization:\n",
    "        control_array += np.ones_like(labels_array) * facenet.FIXED_STANDARDIZATION\n",
    "    if use_flipped_images:\n",
    "        control_array += (labels_array % 2) * facenet.FLIP\n",
    "    sess.run(enqueue_op, {image_paths_placeholder: image_path_array, labels_placeholder: labels_array, \n",
    "                          control_placeholder: control_array})\n",
    "    \n",
    "    assert num_images % batch_size == 0, 'The number of LFW images must be an integer multiple of the LFW batch size'\n",
    "    num_batches = num_images // batch_size\n",
    "    embedding_size = int(embeddings.get_shape()[1])\n",
    "    embedding_array = np.zeros((num_images, embedding_size))\n",
    "    pred_label_array = np.zeros((num_images, ))\n",
    "    for i in range(num_batches):\n",
    "        feed_dict = {phase_train_placeholder: False, batch_size_placeholder: batch_size}\n",
    "        _embedding, _pred_label = sess.run([embeddings, labels], feed_dict=feed_dict)\n",
    "        pred_label_array[_pred_label] = _pred_label\n",
    "        embedding_array[_pred_label, :] = _embedding\n",
    "        if i % 10 == 9:\n",
    "            print('.', end='')\n",
    "            sys.stdout.flush()\n",
    "    print('')\n",
    "    \n",
    "    embeddings = np.zeros((num_embeddings, embedding_size * num_flips))\n",
    "    if use_flipped_images:\n",
    "        embeddings[:, :embedding_size] = embedding_array[0::2, :]\n",
    "        embeddings[:, embedding_size:] = embedding_array[1::2, :]\n",
    "    else:\n",
    "        embeddings = embedding_array\n",
    "    \n",
    "    assert np.array_equal(lab_array, np.arange(nrof_images))==True, \\\n",
    "    'Wrong labels used for evaluation, possibly caused by training examples left in the input pipeline'    \n",
    "    \n",
    "    _, _, accuracy, val, val_std, far = lfw.evaluate(embeddings, actual_issame, nrof_folds=nrof_folds, \n",
    "                                                     distance_metric=distance_metric, subtract_mean=subtract_mean)\n",
    "    \n",
    "    print('Accuracy: %2.5f+-%2.5f' % (np.mean(accuracy), np.std(accuracy)))\n",
    "    print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))\n",
    "    lfw_time = time.time() - start_time\n",
    "    # Add validation loss and accuracy to summary\n",
    "    summary = tf.Summary()\n",
    "    #pylint: disable=maybe-no-member\n",
    "    summary.value.add(tag='lfw/accuracy', simple_value=np.mean(accuracy))\n",
    "    summary.value.add(tag='lfw/val_rate', simple_value=val)\n",
    "    summary.value.add(tag='time/lfw', simple_value=lfw_time)\n",
    "    summary_writer.add_summary(summary, step)\n",
    "    with open(os.path.join(log_dir,'lfw_result.txt'),'at') as f:\n",
    "        f.write('%d\\t%.5f\\t%.5f\\n' % (step, np.mean(accuracy), val))\n",
    "    stat['lfw_accuracy'][epoch-1] = np.mean(accuracy)\n",
    "    stat['lfw_valrate'][epoch-1] = val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow3)",
   "language": "python",
   "name": "tensorflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
