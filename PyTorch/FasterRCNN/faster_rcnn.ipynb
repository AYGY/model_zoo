{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(argv):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--dataset_dir', default='/home/lzhang/pascal/VOC2012/', type=str, help='training dataset dir')\n",
    "    parser.add_argument('--dataset_split', default='trainval', type=str, help='training dataset split')\n",
    "    parser.add_argument('--net', default='vgg16', type=str, help='vgg16, res101')\n",
    "    parser.add_argument('--min_size', default=600, type=int, help='min image resize')\n",
    "    parser.add_argument('--max_size', default=1000, type=int, help='max image resize')\n",
    "    parser.add_argument('--num_workers', default=8, type=int, help='number of worker to load data')\n",
    "    \n",
    "    parser.add_argument('--rpn_sigma', default=3, type=int, help='rpn sigma for l1_smooth_loss')\n",
    "    parser.add_argument('--roi_sigma', default=1, type=int, help='roi sigma for l1_smooth_loss')\n",
    "    \n",
    "    parser.add_argument('--lr', default=0.001, type=float, help='starting learning rate')\n",
    "    parser.add_argument('--lr_decay_step', default=5, type=int, help='epoch to do learning rate decay')\n",
    "    parser.add_argument('--lr_decay_gamma', default=0.1, type=float, help='learning rate decay ratio')\n",
    "    parser.add_argument('--weight_decay', default=0.0005, type=float, help='weight decay ratio')\n",
    "    parser.add_argument('--epochs', default=20, type=int, help='number of epochs to train')\n",
    "    parser.add_argument('--optimizer', default=\"sgd\", type=str, help='training optimizer')\n",
    "    parser.add_argument('--batch_size', default=1, type=int, help='batch_size')    \n",
    "    parser.add_argument('--cuda', action='store_true', help='whether use CUDA')\n",
    "    \n",
    "    parser.add_argument('--visdom_env', default='faster_rcnn', type=str, help='visdom env')\n",
    "    parser.add_argument('--visdom_port', default='8097', type=str, help='visdom port')\n",
    "    \n",
    "    parser.add_argument('--plot_every', default=100, type=int, help='number of iterations to plot')\n",
    "    parser.add_argument('--save_ckpt_every', default=10000, type=int, help='number of iterations to save checkpoint.')\n",
    "    parser.add_argument('--save_dir', default=\"/home/lzhang/pytorch/models\", type=str, help='directory to save models')\n",
    "\n",
    "    parser.add_argument('--debug', action='store_true', help='if print debug msg')   \n",
    "\n",
    "    return parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 353, 3)\n",
      "(850, 600, 3)\n",
      "torch.Size([1, 18, 53, 37])\n",
      "torch.Size([1, 36, 53, 37])\n"
     ]
    }
   ],
   "source": [
    "from model.faster_rcnn_vgg16 import FasterRCNNVGG16\n",
    "from model.feature_extraction_network import FeatureExtractionNetwork\n",
    "from model.region_proposal_network import RegionProposalNetwork\n",
    "from model.anchor_generator import AnchorGenerator, AnchorTargetGenerator\n",
    "from model.proposal_generator import ProposalGenerator\n",
    "from data.dataset import VOCBboxDataSet\n",
    "\n",
    "import cv2\n",
    "from data import data_util\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "img_file = '/home/lzhang/tmp/000001.jpg'\n",
    "anno_file = '/home/lzhang/tmp/000001.xml'\n",
    "\n",
    "def get_bbox(anno):\n",
    "    bbox = []\n",
    "    for obj in anno.findall('object'):\n",
    "        bndbox_anno = obj.find('bndbox')\n",
    "        bbox.append([int(bndbox_anno.find(tag).text) - 1 for tag in ('xmin', 'ymin', 'xmax', 'ymax')])\n",
    "\n",
    "    bbox = np.stack(bbox).astype(np.float32)\n",
    "    return bbox\n",
    "\n",
    "def train(args):\n",
    "    img = cv2.imread(img_file)\n",
    "    print(img.shape)\n",
    "    img, scale = data_util.resize_img(img)\n",
    "    print(img.shape)\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    img_size = (height, width)\n",
    "    \n",
    "#     vgg16 = FeatureExtractionNetwork()\n",
    "#     extractor = vgg16.features\n",
    "#     features = extractor(t.from_numpy(np.expand_dims(img, axis=0).transpose((0, 3, 1, 2))).type(t.float))\n",
    "#     print(features.shape)\n",
    "    \n",
    "    anno = ET.parse(anno_file)\n",
    "    bbox = get_bbox(anno)\n",
    "    \n",
    "    anchor_generator = AnchorGenerator()\n",
    "    anchors = anchor_generator(img_size)\n",
    "    \n",
    "    anchor_reg_target_generator = AnchorTargetGenerator()\n",
    "    anchor_reg_target_generator(img_size, anchors, bbox)\n",
    "    \n",
    "    faster_rcnn_vgg16 = FasterRCNNVGG16()\n",
    "    faster_rcnn_vgg16(img, bbox, scale)\n",
    "    \n",
    "#     proposal_generator = ProposalGenerator()\n",
    "#     proposal_generator()\n",
    "\n",
    "train(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.utils import bbox2reg, reg2bbox, bbox_transform, bbox_transform_inv\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "src_bbox = np.array([1.0, 2.0, 3.0, 4.0]).reshape(-1, 4)\n",
    "dst_bbox = np.array([5.4, 6.24, 12.1, 13.1]).reshape(-1, 4)\n",
    "\n",
    "reg = bbox2reg(src_bbox, dst_bbox)\n",
    "dst_bbox2 = reg2bbox(src_bbox, reg)\n",
    "# print(reg)\n",
    "print(dst_bbox2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from model.utils import non_maximum_suppression\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed( 1 )   # keep fixed\n",
    "num_rois = 6000\n",
    "minxy = np.random.randint(50,145,size=(num_rois ,2))\n",
    "maxxy = np.random.randint(150,200,size=(num_rois ,2))\n",
    "\n",
    "score = 0.8*np.random.random_sample((num_rois ,1))+0.2\n",
    "order = score.ravel().argsort()[::-1]\n",
    "\n",
    "boxes_new = np.concatenate((minxy, maxxy), axis=1).astype(np.float32)\n",
    "boxes_new = boxes_new[order, :]\n",
    "\n",
    "keep = non_maximum_suppression(boxes_new, thresh=0.7)\n",
    "print(len(keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from model.utils import non_maximum_suppression, py_cpu_nms\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "np.random.seed( 1 )   # keep fixed\n",
    "num_rois = 6000\n",
    "minxy = np.random.randint(50,145,size=(num_rois ,2))\n",
    "maxxy = np.random.randint(150,200,size=(num_rois ,2))\n",
    "score = 0.8*np.random.random_sample((num_rois ,1))+0.2\n",
    "\n",
    "boxes_new = np.concatenate((minxy,maxxy,score), axis=1).astype(np.float32)\n",
    "\n",
    "def nms_test_time(boxes_new):\n",
    "\n",
    "    thresh = [0.7,0.8,0.9]\n",
    "    T = 1\n",
    "    for i in range(len(thresh)):\n",
    "        since = time.time()\n",
    "        for t in range(T):\n",
    "            keep = py_cpu_nms(boxes_new, thresh=thresh[i])     # for cpu\n",
    "            print(len(keep))\n",
    "        print(\"thresh={:.1f}, time wastes:{:.4f}\".format(thresh[i], (time.time()-since)/T))\n",
    "    return keep\n",
    "\n",
    "nms_test_time(boxes_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17649, 4)\n",
      "(17649, 4)\n",
      "(14690, 4)\n",
      "(12000, 4)\n",
      "4230\n",
      "(2000, 4)\n",
      "torch.Size([2000, 21])\n",
      "torch.Size([2000, 84])\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(batch_size=1, cuda=False, dataset_dir='/home/lzhang/pascal2/VOC2007/', dataset_split='train_test', training=True, debug=False, epochs=20, lr=0.001, lr_decay_gamma=0.1, lr_decay_step=5, max_size=1000, min_size=600, net='vgg16', num_workers=8, optimizer='sgd', plot_every=100, random_hflip_ratio=0.5, return_difficult=False, roi_sigma=1, rpn_sigma=3, save_ckpt_every=10000, save_dir='/home/lzhang/pytorch/models', use_data_aug=False, use_difficult=False, visdom_env='faster_rcnn', visdom_port='8097', weight_decay=0.0005)\n",
    "\n",
    "from data.dataset import VOCBboxDataSet\n",
    "from model.faster_rcnn_vgg16 import FasterRCNNVGG16\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "dataset = VOCBboxDataSet(args)\n",
    "data = dataset[0]\n",
    "print(data.anchors.shape)\n",
    "\n",
    "net = FasterRCNNVGG16()\n",
    "res = net(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.asarray([1, 2, 3, 4, 5, 6]).reshape((2, 3))\n",
    "b = np.where(a > 4)\n",
    "print(a[b[1][0], b[1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3",
   "language": "python",
   "name": "pytorch3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
